{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 농업 환경 변화에 따른 작물 병해 진단 AI 경진대회"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision import transforms as T\n",
    "import timm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils import CosineAnnealingWarmUpRestarts, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focus augmentation\n",
    "\n",
    "바운딩 박스 좌표를 활용해 주변 배경을 제거한 객체 사진을 따로 저장하여 학습과정에서 데이터 증강기법으로 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 전체 복사\n",
    "# for path in tqdm(glob.glob('data/train/*'),position=0):\n",
    "#     shutil.copytree(path,f'{path}_focus')\n",
    "# #각 파일 포맷들 이름 변경\n",
    "# for sample in tqdm(glob.glob('data/train/*focus/*.csv'),position=0):\n",
    "#     os.rename(sample,f'{sample[:-4]}_focus.csv')\n",
    "\n",
    "# for sample in tqdm(glob.glob('data/train/*focus/*.json'),position=0):\n",
    "#     os.rename(sample,f'{sample[:-5]}_focus.json')\n",
    "\n",
    "# for sample in tqdm(glob.glob('data/train/*focus/*.jpg'),position=0):\n",
    "#     os.rename(sample,f'{sample[:-4]}_focus.jpg')\n",
    "\n",
    "# # 객체 영역만 저장\n",
    "# for sample in tqdm(glob.glob('data/train/*focus'),position=0):\n",
    "#     img_path = glob.glob(f'{sample}/*.jpg')[0]\n",
    "#     sample_image = cv2.imread(img_path)\n",
    "#     sample_json = json.load(open(glob.glob(f'{sample}/*.json')[0],'r'))\n",
    "#     points = sample_json['annotations']['bbox'][0]\n",
    "#     x= int(points['x'])\n",
    "#     y= int(points['y'])\n",
    "#     w= int(points['w'])\n",
    "#     h= int(points['h'])\n",
    "#     crop_focus = sample_image[y:y+h,x:x+w,:].copy()\n",
    "#     cv2.imwrite(img_path,crop_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Csv feature\n",
    "\n",
    "환경 변수에서 학습에 사용할 feature들을 선택 후 미리 최대값, 최솟값을 계산해 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활용할 환경변수 선택\n",
    "# csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
    "#                 '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
    "\n",
    "# csv_files = sorted(glob.glob('data/train/*/*.csv'))\n",
    "\n",
    "\n",
    "# # feature 별 최대값, 최솟값 계산\n",
    "# for csv in tqdm(csv_files[1:],position=0):\n",
    "#     temp_csv = pd.read_csv(csv)[csv_features]\n",
    "#     temp_csv = temp_csv.replace('-',np.nan).dropna()\n",
    "#     if len(temp_csv) == 0:\n",
    "#         continue\n",
    "#     temp_csv = temp_csv.astype(float)\n",
    "#     temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
    "#     max_arr = np.max([max_arr,temp_max], axis=0)\n",
    "#     min_arr = np.min([min_arr,temp_min], axis=0)\n",
    "\n",
    "# # feature 별 최대값, 최솟값 dictionary 생성\n",
    "# csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
    "\n",
    "# 구해 놓은 값 저장\n",
    "# with open('csv_minmax.pickle','wb') as f:\n",
    "#     pickle.dump(csv_feature_dict, f)\n",
    "\n",
    "# 미리 저장한 값 읽어오기\n",
    "with open('csv_minmax.pickle', 'rb') as f:\n",
    "    csv_feature_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV를 사용하여 label을 생성하기 위한 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = {'1':'딸기','2':'토마토','3':'파프리카','4':'오이','5':'고추','6':'시설포도'}\n",
    "disease = {'1':{'a1':'딸기잿빛곰팡이병','a2':'딸기흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '2':{'a5':'토마토흰가루병','a6':'토마토잿빛곰팡이병','b2':'열과','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '3':{'a9':'파프리카흰가루병','a10':'파프리카잘록병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '4':{'a3':'오이노균병','a4':'오이흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '5':{'a7':'고추탄저병','a8':'고추흰가루병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
    "           '6':{'a11':'시설포도탄저병','a12':'시설포도노균병','b4':'일소피해','b5':'축과병'}}\n",
    "risk = {'1':'초기','2':'중기','3':'말기'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_description = {}\n",
    "for key, value in disease.items():\n",
    "    label_description[f'{key}_00_0'] = f'{crop[key]}_정상'\n",
    "    for disease_code in value:\n",
    "        for risk_code in risk:\n",
    "            label = f'{key}_{disease_code}_{risk_code}'\n",
    "            label_description[label] = f'{crop[key]}_{disease[key][disease_code]}_{risk[risk_code]}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = {key: idx for idx,key in enumerate(label_description)}\n",
    "label_decoder = {val:key for key, val in label_encoder.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, files, labels=None, mode ='train', csv_feature_dict=None,label_encoder=None,transform=None):\n",
    "        self.mode = mode\n",
    "        self.files = files\n",
    "        self.csv_feature_dict = csv_feature_dict\n",
    "        \n",
    "        self.csv_feature_check = [0]*len(self.files)\n",
    "        self.csv_features = [None]*len(self.files)\n",
    "        \n",
    "        self.max_len = 24 * 6\n",
    "        self.label_encoder = label_encoder\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        file = self.files[i]\n",
    "        file_name = file.split('\\\\')[-1]\n",
    "        \n",
    "        #csv\n",
    "        if self.csv_feature_check[i] == 0:\n",
    "            csv_path = f'{file}/{file_name}.csv'\n",
    "            df = pd.read_csv(csv_path)[self.csv_feature_dict.keys()]\n",
    "            df = df.replace('-', 0)\n",
    "            # MinMax scaling\n",
    "            for col in df.columns:\n",
    "                df[col] = df[col].astype(float) - self.csv_feature_dict[col][0]\n",
    "                df[col] = df[col] / (self.csv_feature_dict[col][1]-self.csv_feature_dict[col][0])\n",
    "            # zero padding\n",
    "            pad = np.zeros((self.max_len, len(df.columns)))\n",
    "            length = min(self.max_len, len(df))\n",
    "            pad[-length:] = df.to_numpy()[-length:]\n",
    "            # transpose to sequential data\n",
    "            csv_feature = pad.T\n",
    "            self.csv_features[i] = csv_feature\n",
    "            self.csv_feature_check[i] = 1\n",
    "        else:\n",
    "            csv_feature = self.csv_features[i]\n",
    "        #image\n",
    "        image_path = f'{file}/{file_name}.jpg'\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            image_transform = self.transform(image=image)\n",
    "            image = image_transform['image']\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            json_path = f'{file}/{file_name}.json'\n",
    "            with open(json_path, 'r') as f:\n",
    "                json_file = json.load(f)\n",
    "            \n",
    "            crop = json_file['annotations']['crop']\n",
    "            disease = json_file['annotations']['disease']\n",
    "            risk = json_file['annotations']['risk']\n",
    "            label = f'{crop}_{disease}_{risk}'\n",
    "            \n",
    "            return {\n",
    "                'img' : image,\n",
    "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32),\n",
    "                'label' : torch.tensor(self.label_encoder[label], dtype=torch.long)\n",
    "            }\n",
    "        elif self.mode =='val':\n",
    "            json_path = f'{file}/{file_name}.json'\n",
    "            with open(json_path, 'r') as f:\n",
    "                json_file = json.load(f)\n",
    "            \n",
    "            crop = json_file['annotations']['crop']\n",
    "            disease = json_file['annotations']['disease']\n",
    "            risk = json_file['annotations']['risk']\n",
    "            label = f'{crop}_{disease}_{risk}'\n",
    "            \n",
    "            return {\n",
    "                'img' : image,\n",
    "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32),\n",
    "                'label' : torch.tensor(self.label_encoder[label], dtype=torch.long)\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            return {\n",
    "                'img' :image,\n",
    "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32)\n",
    "            }\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin = [path for path in sorted(glob.glob('data/train/*')) if not path.endswith('focus')]\n",
    "train_focus = [path for path in sorted(glob.glob('data/train/*')) if path.endswith('focus')]\n",
    "\n",
    "test = sorted(glob.glob('data/test/*'))\n",
    "\n",
    "train_label = pd.read_csv('data/train.csv')['label']\n",
    "\n",
    "train, val = train_test_split(train_origin, test_size=0.2, stratify=train_label)\n",
    "\n",
    "train = train+train_focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "batch_size = 16\n",
    "class_n = len(label_encoder)\n",
    "learning_rate = 1e-4#0.025\n",
    "embedding_dim = 512\n",
    "num_features = len(csv_feature_dict)\n",
    "max_len = 24*6\n",
    "dropout_rate = 0.4\n",
    "epochs = 1500\n",
    "vision_pretrain = True\n",
    "save_path = 'model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "h,w = 512,384\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(h, w), \n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    A.Normalize(IMAGENET_MEAN,IMAGENET_STD),\n",
    "    ToTensorV2()\n",
    "])\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(h, w), \n",
    "    A.Normalize(IMAGENET_MEAN,IMAGENET_STD),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(files=train,\n",
    "                              mode='train',\n",
    "                              csv_feature_dict=csv_feature_dict,\n",
    "                              label_encoder=label_encoder,\n",
    "                              transform=train_transform)\n",
    "\n",
    "val_dataset = CustomDataset(files=val,\n",
    "                            mode='val',\n",
    "                            csv_feature_dict=csv_feature_dict,\n",
    "                            label_encoder=label_encoder,\n",
    "                            transform=test_transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,  shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- pretrained model : densenet201 from torchvision.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Encoder(nn.Module):\n",
    "    def __init__(self, class_n, rate=0.1):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        self.model = models.densenet201(pretrained=True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Decoder(nn.Module):\n",
    "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
    "        super(RNN_Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(max_len, embedding_dim)\n",
    "        self.rnn_fc = nn.Linear(num_features*embedding_dim, 1000)\n",
    "        self.pre_final_layer = nn.Linear(1000 + 1000, 512) # resnet out_dim + lstm out_dim\n",
    "        self.final_layer = nn.Linear(512, class_n) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "\n",
    "    def forward(self, enc_out, dec_inp):\n",
    "        hidden, _ = self.lstm(dec_inp)\n",
    "        hidden = hidden.view(hidden.size(0), -1)\n",
    "        hidden = self.rnn_fc(hidden)\n",
    "        concat = torch.cat([enc_out, hidden], dim=1) # enc_out + hidden \n",
    "        fc_input = concat\n",
    "        output = self.relu(self.dropout((self.pre_final_layer(fc_input))))\n",
    "        output = self.final_layer(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2RNN(nn.Module):\n",
    "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
    "        super(CNN2RNN, self).__init__()\n",
    "        self.cnn = CNN_Encoder(embedding_dim, rate)\n",
    "        self.rnn = RNN_Decoder(max_len, embedding_dim, num_features, class_n, rate)\n",
    "        \n",
    "    def forward(self, img, seq):\n",
    "        cnn_output = self.cnn(img)\n",
    "        output = self.rnn(cnn_output, seq)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN2RNN(max_len=max_len, embedding_dim=embedding_dim, num_features=num_features, class_n=class_n, rate=dropout_rate)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):    \n",
    "    real = real.cpu()\n",
    "    pred = torch.argmax(pred, dim=1).cpu()\n",
    "    score = f1_score(real, pred, average='macro')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_item, training):\n",
    "    img = batch_item['img'].to(device)\n",
    "    csv_feature = batch_item['csv_feature'].to(device)\n",
    "    label = batch_item['label'].to(device)\n",
    "    if training is True:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(img, csv_feature)\n",
    "            loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        score = accuracy_function(label, output)\n",
    "        return loss, score\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(img, csv_feature)\n",
    "            loss = criterion(output, label)\n",
    "        score = accuracy_function(label, output)\n",
    "        return loss, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot, val_loss_plot = [], []\n",
    "metric_plot, val_metric_plot = [], []\n",
    "max_f1_score = 0\n",
    "patience=50\n",
    "early_stopping = EarlyStopping(patience = patience, verbose = True, path =save_path )\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'{epoch+1} epoch start LR : {lr:.2e}')\n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    total_acc, total_val_acc = 0, 0\n",
    "    \n",
    "    with tqdm(enumerate(train_dataloader),total = len(train_dataloader), unit=\"batch\",position=0) as tepoch:\n",
    "        training = True\n",
    "        for batch, batch_item in tepoch:\n",
    "            batch_loss, batch_acc = train_step(batch_item, training)\n",
    "            total_loss += batch_loss\n",
    "            total_acc += batch_acc\n",
    "\n",
    "            tepoch.set_postfix({\n",
    "                'Epoch': epoch + 1,\n",
    "                'Loss': '{:06f}'.format(batch_loss.item()),\n",
    "                'Mean Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
    "                'Mean F-1' : '{:06f}'.format(total_acc/(batch+1))\n",
    "            })\n",
    "        loss_plot.append(total_loss/(batch+1))\n",
    "        metric_plot.append(total_acc/(batch+1))\n",
    "    \n",
    "    with tqdm(enumerate(val_dataloader),total = len(val_dataloader), unit=\"batch\",position=0) as tepoch:\n",
    "        training = False\n",
    "        for batch, batch_item in tepoch:\n",
    "            batch_loss, batch_acc = train_step(batch_item, training)\n",
    "            total_val_loss += batch_loss\n",
    "            total_val_acc += batch_acc\n",
    "\n",
    "            tepoch.set_postfix({\n",
    "                'Epoch': epoch + 1,\n",
    "                'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
    "                'Mean Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
    "                'Mean Val F-1' : '{:06f}'.format(total_val_acc/(batch+1))\n",
    "            })\n",
    "        val_loss_plot.append(total_val_loss/(batch+1))\n",
    "        val_metric_plot.append(total_val_acc/(batch+1))\n",
    "    \n",
    "    \n",
    "    scheduler.step(val_loss_plot[-1])\n",
    "    \n",
    "    \n",
    "    early_stopping(-val_metric_plot[-1], model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(files=test,\n",
    "                            mode = 'test',\n",
    "                            csv_feature_dict=csv_feature_dict,\n",
    "                            label_encoder=label_encoder,\n",
    "                            transform=test_transform)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256,  shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'model384.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 203/203 [18:51<00:00,  5.57s/batch]\n"
     ]
    }
   ],
   "source": [
    "def predict(data_loader):\n",
    "    model.eval()\n",
    "    with tqdm(enumerate(data_loader),total = len(data_loader), unit=\"batch\",position=0) as tepoch:\n",
    "        results = []\n",
    "        for batch, batch_item in tepoch:\n",
    "            img = batch_item['img'].to(device)\n",
    "            seq = batch_item['csv_feature'].to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(img, seq)\n",
    "            output = torch.argmax(output,dim=1).detach().cpu().numpy()\n",
    "            results.extend(output)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "model = CNN2RNN(max_len=max_len, embedding_dim=embedding_dim, num_features=num_features, class_n=class_n, rate=dropout_rate)\n",
    "model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "model = model.to(device)\n",
    "\n",
    "preds = predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_label = np.array([label_decoder[int(val)] for val in preds])\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['label'] = preds\n",
    "submission.to_csv('data/submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
